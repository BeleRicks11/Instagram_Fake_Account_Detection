{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6ds4FJBBIr5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../DataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "CkRdhCBIBQQh",
    "outputId": "7e6fd6c8-18b0-4663-9529-f0bf04dfa7f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile Pic</th>\n",
       "      <th>Nums/Length Username</th>\n",
       "      <th>Full Name Words</th>\n",
       "      <th>Bio Length</th>\n",
       "      <th>External Url</th>\n",
       "      <th>Private</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Business</th>\n",
       "      <th>#Posts</th>\n",
       "      <th>#Followers</th>\n",
       "      <th>#Following</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>678</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.067</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>334</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>539</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>3098</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>496</td>\n",
       "      <td>1079</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>661</td>\n",
       "      <td>1562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>296</td>\n",
       "      <td>4909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>6108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Profile Pic  Nums/Length Username  Full Name Words  Bio Length  \\\n",
       "0               1                 0.000                2          42   \n",
       "1               1                 0.067                2           0   \n",
       "2               1                 0.000                0           0   \n",
       "3               1                 0.000                2          14   \n",
       "4               1                 0.000                2           0   \n",
       "...           ...                   ...              ...         ...   \n",
       "1195            1                 0.000                2           2   \n",
       "1196            0                 0.000                0           0   \n",
       "1197            1                 0.000                2          58   \n",
       "1198            1                 0.143                1           0   \n",
       "1199            1                 0.000                1           0   \n",
       "\n",
       "      External Url  Private  Verified  Business  #Posts  #Followers  \\\n",
       "0                1        0         0         0     102         678   \n",
       "1                0        0         0         0      58         334   \n",
       "2                0        0         0         0      44         539   \n",
       "3                0        0         0         0     188        3098   \n",
       "4                0        0         0         1     496        1079   \n",
       "...            ...      ...       ...       ...     ...         ...   \n",
       "1195             0        1         0         0       8         661   \n",
       "1196             0        0         0         0       0           2   \n",
       "1197             0        1         0         0      47         296   \n",
       "1198             0        1         0         0       0           5   \n",
       "1199             0        0         0         0       3          81   \n",
       "\n",
       "      #Following  Fake  \n",
       "0            405     0  \n",
       "1            434     0  \n",
       "2            364     0  \n",
       "3            286     0  \n",
       "4           1979     0  \n",
       "...          ...   ...  \n",
       "1195        1562     1  \n",
       "1196         223     1  \n",
       "1197        4909     1  \n",
       "1198          67     1  \n",
       "1199        6108     1  \n",
       "\n",
       "[1200 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "n_1WSismBapB",
    "outputId": "c3f89707-f83a-4aeb-dfd8-4c2fbcedee53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   0.,   2.,  42.,   1.,   0.,   0.,   0., 102., 678., 405.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set X array, containing all the values to valuate a Fake Account\n",
    "X = df.iloc[:, 0:11].values\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LZmNKy1TBekY",
    "outputId": "081d6bdb-dc23-4198-a645-70e2412614f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign y and print \n",
    "y=df.iloc[:,11].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0cNVdmhIBhBQ",
    "outputId": "95ccaeab-3f7b-40ef-e061-e652ff531c2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "   The features are considered unimportant and removed, if the corresponding coef_ or feature_importances_ \n",
    "   values are below the provided threshold parameter. Apart from specifying the threshold numerically, \n",
    "   there are built-in heuristics for finding a threshold using a string argument. Available heuristics are \n",
    "   “mean”, “median” and float multiples of these like “0.1*mean”.\n",
    "\"\"\"\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Used when the goal is to reduce the dimensionality of the data to use\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-U6Ck6RlCoGr",
    "outputId": "ae4264b6-51e8-431d-914a-c7e3e1339f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "2hD7b2-2Jsq_",
    "outputId": "9c251187-ca89-4827-8746-afcc90a19173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.,  42., 102., 678., 405.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "3HKy4qV2gykh",
    "outputId": "dc0ffebd-a435-4eaa-8abe-1ff771f5a165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 4 (0.344536) #Following\n",
      "2. feature 1 (0.265558) Bio Length\n",
      "3. feature 3 (0.164937) #Followers\n",
      "4. feature 2 (0.144802) #Post\n",
      "5. feature 0 (0.080167) Fullname Words\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Feature Importance Forest of Trees\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_new, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "def printColumn(number):\n",
    "  switcher = {\n",
    "      0: \"Fullname Words\",\n",
    "      1: \"Bio Length\",\n",
    "      2: \"#Post\",\n",
    "      3: \"#Followers\",\n",
    "      4: \"#Following\"\n",
    "  }\n",
    "  return switcher.get(number, \"Invalid Column\")\n",
    "\n",
    "for f in range(X_new.shape[1]):\n",
    "    print(\"%d. feature %d (%f) %s\" % (f + 1, indices[f], importances[indices[f]], printColumn(indices[f])))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_new.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_new.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "96PtVsxmhEYl",
    "outputId": "03c74627-664d-4999-b1f6-7d81b6e0e58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804 804\n",
      "396 396\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "TRAIN SET 1.0\n",
      "TEST  SET 0.9595959595959596\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  Decision Tree Classifier\n",
    "\"\"\"\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_new, y)\n",
    "\n",
    "# Train and Test algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "\n",
    "print(clf.fit(X_train, y_train))\n",
    "\n",
    "print(\"TRAIN SET\", clf.score(X_train, y_train))\n",
    "print(\"TEST  SET\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " L1-based feature selection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
